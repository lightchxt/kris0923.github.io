<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>《C程序设计语言学习笔记》（一）</title><url>/post/c-language/</url><categories><category>C</category></categories><tags><tag>C</tag><tag>编程语言</tag></tags><content type="html"><![CDATA[1. 导言 在第一章中，K&amp;R C介绍了C语言的一些基础知识，包括for循环语句、if-else语句、字符输入和输出等内容。
for 语句 for循环语句是C语言中很常见的一种循环结构，其语法如下：
for (expr1; expr2; expr3)  statement 其中，expr1是初始化表达式；expr2是关系表达式，它会在每次循环开始前对其求值；expr3是更新表达式，它会在每次循环结束后对其求值；statement是需要循环执行的语句。
符号常量 在程序中，经常需要使用一些固定的数值或字符串。为了避免在程序中多次书写这些数值或字符串，C语言提供了符号常量的功能。符号常量可以使用#define命令来定义，例如：
#define MAXLINE 1000 这样就定义了一个名为MAXLINE的符号常量，并将它的值设置为1000。之后，在程序中只要写MAXLINE就可以代表1000。
字符输入/输出 C语言提供了多种输入和输出函数。在第一章中介绍了两个最基本的函数，分别是getchar和putchar。getchar函数用于从标准输入流中获取一个字符，putchar函数用于向标准输出流中输出一个字符。
数组 在C语言中，数组是一组同类型的变量序列。数组中的每个元素都可以通过下标来访问，下标从0开始。例如，下标为0的元素可以通过a[0]来访问。
函数 C语言中的函数是一段具有特定功能的代码，可以被多次调用。在程序中使用函数可以使程序更加模块化，也可以提高代码可重用性。
参数-传值调用 C语言中使用参数来向函数中传递值。在函数中，参数是以传值的方式进行传递的，这意味着在函数内部对参数进行修改不会影响函数外部的变量。
字符数组 C语言中的字符串是由一系列字符组成的数组。在处理字符串时，经常需要使用字符数组。例如，可以使用strcpy函数将一个字符串复制到另一个字符数组中。
外部变量与作用域 C语言中，变量可以定义在函数的内部或外部。在函数外部定义的变量称为外部变量。外部变量必须定义在所有函数之外，并且只能定义一次。变量的作用域是指在程序中可以被访问的范围。
2. 类型、运算符与表达式 在第二章中，K&amp;R C介绍了C语言的数据类型、运算符和表达式相关的知识。
变量名 在C语言中，变量名可以包含字母、数字和下划线。不建议使用以下划线开头的变量名，也不能以数字开头。
数据类型及长度 C语言中有几种基本数据类型，包括char、int、float和double等。除了这些基本类型，还有一些限定符，例如short、long、unsigned和signed等。
常量 在C语言中，常量是不可修改的值。常量可以是字面值、符号常量或枚举常量等。
声明 在C语言中，所有的变量都必须先声明后使用。声明用于告诉编译器变量的名称、类型和大小等信息。
按位运算符 C语言中提供了许多按位运算符，例如&amp;、|和~等。在进行位运算时，可以使用常量表达式来增加程序的可移植性。
运算符优先级与求值顺序 C语言中的运算符有不同的优先级，如果不清楚优先级，可以使用括号来控制运算次序。C语言不指定同一运算符中多个操作符的计算顺序，例如f() + g()，f() 可能在g() 之前，也可能在g()之后计算。这需要程序员在编程时注意避免造成不必要的困惑和错误。
总之，第一、二章是C语言学习的基础，掌握了这些内容，才能更好地理解后续章节。同时，也需要在实际编程中不断实践和总结，加深对这些知识的理解和掌握。
习题答案 以下是第二章的部分习题答案：
 在C语言中，有几种基本的数据类型？它们分别是什么？  答：在C语言中，有四种基本数据类型，分别是char、int、float和double。
下面哪个变量不能被定义？  a) int _; b) int 1_or_2; c) float x printf; d) double $123_45;
答：b) int 1_or_2;
在C语言中，变量名可以包含哪些字符？有哪些字符不能作为变量名的开头？  答：变量名可以包含字母、数字和下划线。不建议使用以下划线开头的变量名，也不能以数字开头。
假设x和y都是整数，下列赋值语句的含义是什么？  a) x = 10; b) y = ++x;
答：a) 将10赋值给变量x； b) 先将x的值加1，再将结果赋值给y。
下列哪个赋值语句是非法的？  a) x = y = z = 0; b) i = (a = 23, a + 3); c) char c = &lsquo;a&rsquo;, d = &lsquo;b&rsquo;, e = &lsquo;c&rsquo;; d) int a = (3 * 15) + 45;
答：没有非法的赋值语句。
表达式5 * 4 / 2的值是多少？  答：表达式5 * 4 / 2的值是10。
下列哪一对表达式是等价的？  a) (float) i; b) i / 1.0; c) (double) i; d) (float) (i / 1.0);
答：b) i / 1.0和d) (float) (i / 1.0)是等价的。
下列哪个函数用于从标准输入流中读取一个字符？  a) getchar(); b) putchar(); c) gets(); d) scanf();
答：a) getchar()。
下列哪一条语句是错误的？  a) printf(&ldquo;Value = %d\n&rdquo;, value); b) x = -1; c) if (strcmp(s1, s2) == 0) printf(&ldquo;Equal\n&rdquo;); d) value = (val &lt; 0) ? -val : val;
答：没有错误的语句。
下列哪个符号常量不能被定义？  a) #define PI 3.14 b) #define MIN(a,b) ((a) &lt; (b) ? (a) : (b)) c) #define 10_KB 10240 d) #define MAX 1000
答：c) #define 10_KB 10240。符号常量的名称不能以数字开头。
]]></content></entry><entry><title>分布式事务的一致性</title><url>/post/distribute-transaction/</url><categories/><tags/><content type="html">我们都知道数据库事务ACID的特性，在单数据库应用中，通过数据库事务能够很好的保证我们数据的一致性，但是在微服务盛行的今天，单个大系统被拆分为多个小的微服务，每个服务独立部署，并且拥有自己的数据库。这时单纯依靠数据库的事务就无法满足数据一致性的要求，“分布式事务”应运而生。
什么是分布式事务？ 数据库事务有ACID四个特性，理论上分布式事务也应该遵从这四个特性，但是考虑到性能的因素，分布式事务并不能完全实现ACID的特性。实际上数据库事务也没有完全实现ACID，因此才有了事务的四种隔离级别。我们所说的分布式事务都是不完全事务。
分布式事务的解决方案 分布式事务有很多解决方案，比如：2PC、3PC、TCC、Saga和本地消息等等，每个方案适用的场景并不一样，在面临实际需要选择合适的方案。常用的有2PC和本地消息
2PC（二阶段提交） 2PC是 一种常见的分布式事务实现方法，举个例子来说，在电商系统中，下单的时候至少需要做两件事：
写入订单数据
扣减库存
假设订单和库存在两个库中，那我们就必须要保证在下单成功的时候，库存一定被扣减成功了，我们来看看2PC怎么解决这个问题的。2PC引入了一个事务协调者的角色，由协调者提供完整的下单服务，所谓二阶段提交就是准备阶段和提交阶段，在准备阶段，协调者告诉订单系统有新订单了，能不能下单？然后订单系统告诉协调者可以下单，此时协调者再通知库存系统，需要扣减一个库存，库存系统返回可以扣减，当两个系统都返回成功时，协调者再通知订单系统下单，通知库存系统扣减库存（此时才真正的提交事务）
如果准备阶段任意一个系统失败了，那么协调者就要通知两个系统都会滚事务；如果准备阶段都成功了，那么就只有一条路，只能成功，不能失败。
2PC保证了原子性和隔离性，适用于对数据一致性要求比较高的场景，但是，在事务执行的过程中需要阻塞服务端线程和数据库的会话，所以性能不是很高，因此只有在需要强一致且并发量不大的情况下才考虑使用2PC。
本地消息表 在很多情况下，我们可能并不需要数据的强一致性，我们只要保证数据的最终一致性就好了，比如说下单之后需要清空购物车这个操作。这时候可以使用本地消息表来实现分布式事务。
当订单系统收到一个下单请求时，订单系统正常去更新订单数据，在这个过程中在本地记录一条消息日志，内容就是要清空购物车，然后我们再用一个异步的服务去读取本地消息去清空购物车，如果操作失败了，可以通过重试来解决，最终保证订单系统和购物车的数据是一致的。
3PC、TCC大体的思想和2PC是差不多的，解决了一些问题，同时也带来了新的问题，以后再论述。</content></entry><entry><title>GO语言类型转换</title><url>/post/golang/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/</url><categories><category>GOLANG</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[基本数据类型 int 转string var i = 10 s := strconv.Itoa(i) fmt.Printf(&#34;%v&#34;, s) string 转int var s = &#34;10&#34; i, err := strconv.Atoi(s) if err != nil { 	fmt.Println(err) 	return } fmt.Printf(&#34;%v&#34;, i) // int64 ii, err := strconv.ParseInt(s, 10, 32) if err != nil { 	fmt.Println(err) 	return } fmt.Printf(&#34;%v&#34;, ii) // float64 f, err := strconv.ParseInt(s, 10) if err != nil { 	fmt.Println(err) 	return } fmt.Printf(&#34;%v&#34;, f) ]]></content></entry><entry><title>【APUE】高级IO</title><url>/post/apue/%E9%AB%98%E7%BA%A7io/</url><categories><category>读书笔记</category></categories><tags><tag>APUE</tag><tag>Linux</tag></tags><content type="html">非 阻塞IO 系统调用分为两类：“低速”系统调用和其他，低速系统调用可能会使进程永远阻塞：
如果某些文件类型（读管道、终端设备、网络设备）的数据不存在，则读操作可能会使调用者永远阻塞 如果数据不能被相同的文件类型立即接受（管道中无空间、网络流控制），写操作可能会使调用者永远阻塞 在某种条件发生之前打开某种文件类型可能会发生阻塞（如 要打开一个终端设备，需要等待与之连接的调制解调器应答） 对已经加上强制性 记录锁的文件进行读写 某些ioctl操作 某些进程间通信函数 不能讲与磁盘I/O有关的操作视为低速系统调用
记录锁 功能： 当第一个进程正在读或修改这个文件的某个部分时，使用记录锁可以阻止其他进程修改同一文件区
flock： 只能对整个文件加锁 fcntl：支持记录锁功能 lockf： 基于fcntl提供了一个简化的接口 记录锁的自动继承和释放 锁与进程和文件两者相关联：1）当一个进程终止时，它所建立的锁全部释放；2）无论一个描述符何时关闭，该进程通过这一描述符引用的文件上的任何一把锁都会释放 由fork产生的子进程不继承父进程设置的锁 在执行exec后新程序可以继承原执行程序的锁，但是如果对一个文件描述符设置了执行时关闭标志，那么当作为exec的一部分关闭该文件描述符时，将释放相应文件的所有锁 I/O多路转接 select pselect pool 异步I/O 存储映射I/O 将磁盘文件映射到存储空间的一个缓冲区上，从缓冲区中读数据就相当于是读文件中的相应字节
实现 mmap 函数 映射文件的 起始偏移量必须是系统虚拟存储页长度的整数倍， mmap不能将数据添加到文件中，必须要先加长该文件</content></entry><entry><title>【APUE】标准IO库</title><url>/post/apue/standardio/</url><categories><category>读书笔记</category></categories><tags><tag>APUE</tag><tag>Linux</tag></tags><content type="html">1. 缓冲：缓冲的目的是尽可能的减少read或write的次数 全缓冲：填满缓冲区后才尽心实际IO操作 行缓冲：输入和输出遇到换行符的时候，执行IO操作，通常在流涉及终端的时候使用（标准输入和标准输出），在缓冲区满的时候，即使没有换行符，也进行IO操作 不带缓冲：立即输出，标准错误流stderr通常是不带缓冲的 2. IOS C标准： 当且仅当标准输出和标准输入不指向交互式设备时，才能是全缓冲 标准错误绝不会是全缓冲 3. 打开流 Unix环境中使用b作为type的一部分[fopen(file, rb) OR freopen(file, ab+)]实际上没有作用，因为Unix内核并不区分文本文件和二进制文件 进程正常终止（exit或者从main return）所有未带写缓冲数据的标准IO流都将被冲洗（放弃） getc和fgetc的区别在于，getc可以被实现为宏： getc的参数不能是有副作用的表达式 fgetc一定是个函数，一定可以得到地址，可以作为参数传递 fgetc的调用时间可能比getc长（函数调用的时间通常长于宏） 4. 二进制流ß fread和fwrite 可以一次读写一个完整的结构，但是只能用于同一个系统上读写数据，这是因为：
在不同的系统中可能因为系统和编译程序的不同而导致结构成员偏移量的不同 用来存储多字节正数和浮点数的结构在不同的系统上也可能不同</content></entry><entry><title>【APUE】守护进程</title><url>/post/apue/deamon/</url><categories><category>读书笔记</category></categories><tags><tag>APUE</tag><tag>Linux</tag></tags><content type="html">定义 守护进程（daemon）是生存期长的一种进程。通常在系统引导装入时启动
举例 kswapd 守护进程称为内存换页守护进程，支持虚拟内存在子系统在经过一段时间后讲脏页面写回磁盘来回收这些页面 flush 守护进程在可用内存达到设置的最小阈值时讲脏页面冲洗至磁盘；也定期的将脏页面数据冲洗回磁盘来减少在系统出现故障时发生数据丢失。多个冲洗守护进程可以同时存在，每个写回设备都有一个冲洗守护进程 sync_supers 守护进程定期的将文件系统元数据冲洗至磁盘 jbd 守护进程帮助 实现了ext4文件系统中的日志功能 用户层守护进程的父进程时init进程
编程规则 调用umask 将文件创建模式屏蔽字设置为一个已知值（通常是0） 调用fork，然后使父进程 exit 调用setsid创建一个新会话 将工作目录改为根目录 关闭不再需要的文件描述符 某些守护进程打开/dev/null使其具有文件描述符0、1、2，这样任何一个试图读标准输入，写标准输出和错误输出的库例程都不会产生任何效果 出错记录 守护进程没有控制终端，所以不能简单的将消息写到标准错误上，大多数守护进程都使用syslog；
有3种生产日志消息的方法：
内核进程可以调用log函数，任何用户都可以打开并读取/dev/klog设备来读取这些信息 大多数用户进程（守护进程）调用syslog函数生产日志消息，这些消息发送至Unix域数据报套接字/dav/log 无论一个用户是否再此主机上，还是在通过 TCP/IP网络连接到此主机的其他主机上，都可将消息像UDP端口514 单实例守护进程 文件和记录锁机制，在运行程序前，先对文件进行加锁（将进程id写到文件）
惯例 若守护进程是用锁文件，那么该文件通常存储在/var/run目录中 若守护进程支持配置选项，那么配置文件通常存放在/etc目录中，名称通常是name.conf 守护进程可用命令行启动，但他们通常是又系统初始化脚本之一（/etc/rc或者/etc/init.d/）启动的 若一个进程支持配置文件，进程启动时读该文件，但启动之后就不在读该文件；为了避免修改配置后需要重启进程，某些守护进程将捕捉SIGHUP信号，当接收到该信号时重新读配置文件</content></entry><entry><title>【APUE】线程控制</title><url>/post/apue/thread/</url><categories><category>读书笔记</category></categories><tags><tag>APUE</tag><tag>Linux</tag></tags><content type="html">在UNIX系统中，线程提供了分解并发任务的另一种模型
线程终止 单个线程可以通过3种方式退出：
简单的从单个启动例程中返回，返回值是线程的退出码 线程可以被同一进程中的其他线程取消 int pthread_cancel(pthread_t tid) 线程调用pthread_exit #include &amp;lt;pthread.h&amp;gt; void pthread_exit(void *rval_ptr); void pthread_join(pthread_t thread, void **rval_ptr) // 访问线程返回的指针 分配在栈上的变量作为pthread_exit的参数时，其他线程在使用该变量的时候栈上的内容可能已经被更改或撤销，导致程序报错或者访问到错误的数据 线程同步 为了保证每个线程看到一致的数据视图，需要使用互斥量来保证同一时间只有一个线程访问数据
当一个以上的线程需要访问动态分配的对象时，可以在对象中嵌入引用计数
避免死锁 使所有的线程都以相同的顺序加锁 当程序结构复杂时，对互斥量排序比较困难，就需要先释放占有的锁，过一段时间再试 读写锁 三种状态 读模式加锁；写模式加锁；不加锁 当读写锁时写加锁状态时，所有试图对这个锁加锁的线程都会被阻塞；当读模式加锁状态时，所有读模式加锁都可以得到访问权，但是写模式加锁的线程都会阻塞；当有线程试图进行写模式加锁时，之后所有的读模式加锁都会被阻塞。
自旋锁 在获取锁之前一直处于忙等阻塞的状态，适用于：锁被持有的时间短，线程不希望在重新调度上花费太多的成本；在非抢占式内核中非常有用，在用户程序中并不是非常有用
屏障（barrier） 允许某个线程等待，直到所有的合作线程都到达某一点（所有等待的线程都完成工作），然乎从该点继续执行；
线程控制 一个进程可以创建的最大线程数没有确定的限制，但并不是说没有限制； 互斥量属性控制同一线程是否可以对一个互斥量多次加锁 重入 在多任务环境中，一个函数可以在任何时刻中断它，转入OS调度下去执行另外一段代码，而返回控制时不会出现任何错误；
线程安全 如果要一个函数在同一时间点可以被多个线程安全的调用，称该函数是线程安全的 如果一个函数对多个线程来说是可重入的，就说这个函数是线程安全的 线程特定数据（线程私有数据） 查询或存储某个特定线程相关数据的一种机制，，防止某个线程数据于其他线程数据混淆，提供了让基于进程的接口适应多线程环境的机制
线程和信号 一个进程中的信号处理是所有线程共享的
线程和fork 子进程和父进程都没有对内存内容作出改动时，子进程和父进程共享内存页的副本
线程和I/O 进程中所有线程共享文件描述符，文件读取可以使用原子操作</content></entry><entry><title>【APUE】Unix体系结构</title><url>/post/apue/architecture/</url><categories><category>读书笔记</category></categories><tags><tag>APUE</tag><tag>Linux</tag></tags><content type="html"><![CDATA[Unix系统结构从内到外 内核-&gt;系统调用-&gt;(公用函数库、shell)-&gt;应用程序
一般用户信息在/etc/passwd 文件中，但macOS 的passwd文件中只有单用户模式的用户信息，普通登陆用户信息又Open Directory提供
fork 创建一个新进程，新进程是调用进程的一个副本，fork调用一次，返回两次，在父进程中返回子进程ID，在子进程中返回0
Unix系统中有两种时间
 日历时间 （早期的成为格里尼治标准时间） 进程时间（CPU时间）  系统调用和库函数  系统调用：各版本Unix实现的提供良好定义、数量有限、直接进入内核的入口点，成为系统调用 库函数：C语言实现的函数   库函数可以替换，系统调用不能替换
    用户进程 内核     应用程序-&gt;C库函数 系统调用    POSIX POSIX标准定义了7类系统实现的限制和常量，一些常量限制在limits.h（mac /usr/include/limits.h）文件中，sysconf，pathconf，fpathconf可以在运行时得到实际实现值
 与文件和路径有关 pathconf，fpathconf 与文件和路径无关 sysconf  ]]></content></entry><entry><title>Redis数据过期策略</title><url>/post/redis/</url><categories><category>数据库</category></categories><tags><tag>redis</tag></tags><content type="html">1. 数据类型 五种数据类型
2. Redis为什么这么快 Redis是基于内存的操作，CPU不是Redis的瓶颈，内存大小和网络带宽最有可能是Redis的瓶颈； 单线程的效率已经非常高，没有必要使用多线程；单进程避免了线程或线程上下文切换的消耗，以及锁相关问题的消耗 Redis只是处理客户端请求是单线程的，其他事情是在其他进程或线程中进行的，比如RDB文件生成是在子进程中进行 数据结构设计简单，操作方便 3. Redis数据过期策略 3.1 定期删除策略 Redis启用一个定时器监视所有的key，判断key是否过期，过期则删除，这种策略可以保证过期的key最终都被删除，但是每次遍历内存中所有key非常消耗CPU资源。 3.2 惰性删除策略 在获取key时先判断key是否已过期，如果过期则删除，这种策略有个缺点时如果一个key一直未被使用，就一直在内存中，其实它已经过期了，会浪费大量内存空间 两种策略互补，结合起来，定时删除策略每次随机取一部分key进行检查，降低CPU的消耗；惰性删除策略删除访问到的key，基本满足所有的场景；剩余的没被抽到也没有被访问的key，则由内存淘汰策略删除
3.3 内存淘汰策略 1. 当内存不足时，新写入数据报错（Redis默认策略） 2. 当内存不足以容纳新数据时，移除最近最少使用的key（LRU推荐使用） 3. 在键空间中，随机移除某个key 4. 在设置了过期时间的键中，移除最近最少使用的key（Redis既当缓存，又当持久化存储时使用此策略） 5. 在设置了过期时间的key中，随机移除某个key 6. 在设置了过期时间的key中，先过期的key先移除</content></entry><entry><title>一文了解MySql</title><url>/post/mysql/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag></tags><content type="html"><![CDATA[MySlq 逻辑架构 {{ $image := .Resources.GetMatch &ldquo;mysql.png&rdquo; }}
为什么不要使用长事务：  长事务意味着系统里面存在着很老的事务视图，在事务提交之前这些回滚记录都必须保留，导致占用大量的存储空间 占用锁资源，可能拖垮整库  事务的启动方式：  显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接 在set autocommit=0 的情况下，如果是长连接，就有可能导致意外的长事务，所以建议使用set autocommit=1  使用自增ID做主键有什么好处：  二级索引叶子节点占用空间小，int占4字节，bigint 占8字节 自增ID符合B+树索引递增插入的模式，每次插入一条新记录都是追加操作，不会涉及挪动其他数据 用做KV存储的时候才适合用业务ID做主键 MySql 5.6 之后支持了索引下推。减少回表次数  全局锁和表锁： 数据库备份： 对于支持事务的引擎可以使用mysql-dump &ndash;single-transaction来保证视图的一致性，其他的需要使用FTWRL加全局锁来保证 表锁：
 表锁 元数据锁  lock tables &hellip; read/write, unlock tables &hellip; 释放锁 MDL (metadata lock) 不需要显示使用，在访问一个表的时候会自动加上，保证读写的正确性
行锁： 死锁和死锁检测： 出现死锁时有两种策略：  直接进入等待，直到超时，超时时间通过innodb_wait_timeout 来设置 发起死锁检测，发现死锁后主动回滚死锁链条中某一个事务，使其他事务能够继续执行，通过设置innodb_deadlock_decect  死锁检测要消耗大量的CPU资源，所以需要解决热点行更新的性能问题：  临时关掉死锁检测（不可取） 控制并发度，比如控制同一行数据最多只有10个线程在同时更新，做在数据库服务端的中间件 业务上做优化，将一行数据拆分成多行，但业务代码需要考虑详细，如某行数据为0等  乐观锁和悲观锁 乐观锁与悲观锁是从程序员的角度进行划分：
 乐观锁：认为对同一数据的操作并不总发生，实用时间戳或者版本号机制来保证数据操作的排他性 悲观锁：通过数据库本身的锁机制来保证数据的排他性  索引选择：（优化器）  扫描行数 是否回表 是否排序 是否使用临时表 analyize table t 重新统计索引信息  为字符串类型的字段建立索引  使用前缀索引，只使用前n个字符 倒序存储，正着存前n个字符的区分度比较低，如身份证号 hash字段，可能有冲突，需要精确判断字段是否相同  缺点：  前缀索引不能使用覆盖索引 倒序存储和哈希都不支持范围查询  MySql 为什么有时会发生的抖动 当出现以下情况时，系统正在刷脏页：
 redo log满了，正在flush redo log 内存不足，需要淘汰一些内存页，如果是脏页，要回写磁盘，保证每个数据页只有两种状态：   在内存里，内存里就是正确的结果 不在内存中，文件中是正确的结果，这样的话效率最高  MySql认为系统空闲，刷脏页 MySql正常关闭   innodb_io_capacity 控制刷脏页的策略
 Order by 执行过程：  全字段排序（数据单行长度小于max_length_for_sort_data）：从索引中找出满足条件的主键ID，按主键ID取出整行，将查询的字段放入sort_buffer中，然后多sort_buffer中的字段做快速排序（如果数据大于sort_buffer_size，还需要使用外部排序），取前n条记录返回客户端； rowid排序：从索引中找出满足条件的主键ID，按主键ID取出整行，将排序字段和ID放入sort_buffer中，对sort_buffer 中的数据进行排序，取前n行，按主键ID从原表中取出查询字段返回给客户端 两种方式相比：全字段排序需要更多的内存，rowid排序需要再次惠表查询数据  MySql不使用索引的场景：  对索引字段做函数操作 隐式类型转换 字符编码转换 本质是都是：破坏了索引值的有序性：  MySql查询慢的原因  查询长时间不返回：  等MDL锁 等flush 等行锁   查询慢：  没有索引，扫描行数多 事务内一致性读，多次执行undo log    什么情况会出现幻读：  在可重复读的隔离级别下，仅“当前读”才会出现幻读 幻读仅指新插入的行  Gap Lock： 为了解决幻读的问题，但也可能引起死锁（锁住同一个间隙，然后向同一个间隙insert数据）
在读已提交的隔离级别下，没有间隙锁，但是需要把binlog的格式设置为row（statement格式可能日志顺序错乱）
MySql加锁规则：（两个原则，两个优化，一个BUG） 默认在RR隔离级别下
 原则1:加锁的基本单位是next-key lock，是前开后闭区间 原则2:查找过程中访问到的对象才会加锁 优化1:索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁 优化2:索引上的等值查询，向右查询且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁 一个BUG：唯一索引上的范围查询会访问到不满足条件的第一个值为止  间隙锁和间隙锁之间并不冲突，限制的是不能insert
gh-ost MySql Online DDL 工具 pt-query-digist
MySql 如何保证数据不丢：  Bin log的写入机制：事务执行的过程中写把日志写到binlog_cache,事务提交的时候先把binlog_cache写入到binlog文件中 trx running -&gt; binlog_cache -&gt; trx commit-&gt;binlog_file -&gt; fsync disk sync_binlog 控制什么时候fsync到磁盘 sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync； sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 redo log写入机制：  流程： redolog_buffer -&gt; write disk -&gt; fsync(真正持久化)
所以redo log 有三种状态：
 innodb_flush_log_at_trx_commit控制了redolog的写入策略： innodb_flush_log_at_trx_commit = 0， 只写到redolog buffer innodb_flush_log_at_trx_commit = 1，每次事务提交都持久化到磁盘 innodb_flush_log_at_trx_commit = 2，每次事务提交都写到文件系统的page cache中  性能优化：  组提交 binlog_group_commit_sync_delay（延迟多少微秒后才调用 fsync）， binlog_group_commit_sync_no_delay_count（累积多少次以后才调用 fsync） 减少 binlog 的写盘次数 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。  主备一致： 不应该设置binlog_format 为statement，可能会引起主备不一致（加了limit的时候，如果使用的索引不一样，排序可能不同），至少是mixed
每个库的server id 必须不同，生成的binlog中的server id不同，保证不会循环复制
主备延迟的原因：  备库的机器性能比主库差 备库查询压力大 主库执行大事务： 大表的DDL  可靠性优先的主从切换策略：  判断从库的seconds_behind_master小于某个值，比如5s，否则一直重复这一步 主库改readonly=true 判断从库的seconds_behind_master，直到等于0 从库修改readonly=false（可读写状态） 业务请求切换到从库（新主库）  并行复制： coordinator 在分发Relay log的时候，需要满足以下这两个基本要求：
 不能造成覆盖更新，这就要求更新同一行的两个事务必须分发到同一个worker中 同一个事务不能被拆开，必须放到同一个worker中  分发策略：  按表分发，适用于多表的负载均衡，对于热点数据表，可能退化成为单线程复制 按行分发，要求binlog的格式必须是row, 并行度高，但是操作大事务的时候，耗费内存和CPU  Maria 模拟主库的并行，将相同commitID的事务分发给不同的worker，但是也容易被大事务拖后腿
GTID （主从同步） 全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是： GTID=server_uuid:gno
server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值
gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1
读写分离的弊端 两种架构：客户端直连和带Proxy
主从延迟：  强制走主库 sleep（不靠谱） 判断主备无延迟：   a. show salve status 判断second_behind_master是否等于0
  b. Master_Log_File和Relay_master_Log_Pos、Read_Master_Log_Pos 和Exec_Master_Log_Pos 这两组值完全相同（读到主库的最新位点和备库执行的最新位点）
  c. 对比GTID集合，Auto_Position=1, Retrieved_Gtid_set 和 Executed_Gtid_Set两个集合相同
    b，c比a要精确很多，second_behind_master单位是秒
但是b, c 也是完全准确的，可能有一部分binlog正在从主库发送到从库
配合上semi-sync（半同步复制）+位点判断可以解决e的问题，但仅限于一主一从，多从的情况下，一个从库发送ack主库就提交事务了
业务高峰期，主库位点更新很快，所以位点判断一直不相等，可能出现从库迟迟无法响应的情况
等主库位点的方案 主库事务提交后立即执行 show master status，得到当前的file 和position，从库执行select master_pos_wait(File, Position,1),如果大于0，则已包含刚才提交的事务
GTID方案 select wait_for_executed_gtid_set(gtid_set, 1) = 0 表示从库中已经包含传入的gtid_set
5.7 之后的版本会把gtid返回给客户端
MySql健康检查 SHOW VARIABLES LIKE &lsquo;innodb_thread_concurrency&rsquo;; 并发查询数
等行锁和间隙锁的线程是不算在并发查询数里面的 select 1； update 系统表数据 内部统计，判断单次I/O 是否大于某个时间
误删数据找回 误删行 delete  flashback工具，需要保证binlig_format=row和binlog_row_image=FULL 提前预防：设置sql_safe_updates=on, delete 和update的语句中必须有where条件且包含索引字段  误删库/表  全量备份+增量日志 mysqlbinlog 搭建延迟复制备库，指定一个备库和主库有N秒的延迟，减少需要恢复的数据  预防：  帐号分离，不给Drop、truncate的权限 日常使用只读帐号 删表之前，先做更名操作，观察一段时间再删  rm数据  高可用（HA）集群只要不是把整个集群删除，HA会自动选出一个新主库  kill query/ kill connection  MySql kill 和 linux的kill命令类似，并不是直接终止，而是给进程发送一个终止的信号； 把被kill的session的状态改成 THD::KILL_QUERY 给被kill的session  kill 不能生效的情况：  线程没有执行到判断线程状态的逻辑（一直在循环判断是否可以执行） 终止逻辑耗时较长 超大事务执行被kill，回滚操作耗时较长 大查询回滚，生成了比较大的临时文件，如果文件系统压力大，则删除临时文件可能需要等待I/O资源 DDL命令执行到最后阶段，如果被kill，也需要删除过程中的临时文件  读取数据 客户端使用 &ndash;quick 参数会使用mysq_use_result方法 mysql_use_result: 读一行处理一行，如果处理的很慢，客户端过很久才去读下一行，会出现sending to client mysql_store_result: 将查询的结果保存到本地内存 查询结果是分段发送给客户端的，所以不会打爆内存 Innodb Buffer Pull的LRU 算法是用链表实现的，并且分成young区和old区（5：3）；每次淘汰都是在old去，在old区存在超过1s的数据才能进入young区，保证了在全表扫描的时候，正常业务的查询命中率不会降低
Join  如果可以使用被驱动表的索引，join 语句是有其优势的； 不能使用被驱动表的索引，只能使用 Block Nested-Loop Join 算法，这样的语句就尽量不要使用； join_buffer_size 设定了join buffer的大小，越大被驱动表扫描的次数越少，扫描次数 N + k*M 在使用 join 的时候，应该让小表做驱动表 通过where条件过滤之后的数据量小的为小表  Muity-Range Read 优化： 思路：因为大多数数据都是按照主键id自增的顺序插入到得到的，所以按照主键id递增的顺序查询是比较接近顺序读，能够提升读性能 实现：将根据索引定位到的记录放到read_rnd_buffer中，将read_rnd_buffer 中的id递增排序，用排序后的数组到主键索引中查找记录 BKA (Batched Key Access)，对 BNL算法的优化
 在被驱动表上加索引 创建临时表 不支持hash join  临时表的应用  分库分表系统的跨库查询 在使用分区key的查询中可以直接定位到数据放在了哪一个表 未使用到分区key的查询，只能到所有分区中区查找数据，然后统一操作 在proxy中实现，需要的工作量大，对中间层的开发能力比较高，对proxy的压力比较大 把各个分库拿到的数据汇总到一个Mysql实例的一个表中，然后在这个汇总的实力上操作（临时表）  内部临时表 使用场景：  UNION：需要对结果去重，需要使用临时表，Union ALL 就不需要 Group By：无序的数据需要对结果统计计数 如果执行过程可以一边读数据，一边直接得到结果，就不需要额外的内存 join_buffer 是无序数组，sort_buffer是有序数组，临时表是二维表结构 如果需要二维表的特性，就会考虑使用临时表（union 唯一索引约束，group by 需要额外的字段计数） SQL_BIG_RESULT 告诉Mysq 直接使用排序算法得到group by的结果   除了内存临时表，普通的内存表不建议使用，一是不支持行锁，性能可能并没有预想的好，二是在集群架构上数据持久化可能会有问题 主键自增
 innoDB引擎的索引值存在内存里，MyISAM存储在数据文件中，8.0版本之后记录到了redolog中，保证重启也不会丢失
主键自增不连续的原因：  插入数据失败 事务回滚 批量插入，每次申请的自增id的数量都是上一次的两倍，最后未用完的就浪费了  表复制 mysqldump mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction --set-gtid-purged=OFF db1 t --where=&#34;a&gt;900&#34; --result-file=/client_tmp/t.sql 导出csv文件 select * from db1.t where a&gt;900 into outfile &#39;/server_tmp/t.csv&#39;; 生成的文件在服务器上，不在客户端机器上 受 secure_file_priv 的限制 目标文件不存在
物理拷贝 5.6之前是不允许的，5.6之后引入了可传输表空间
Flush Privileges  grant/revoke语句会同时修改数据表和内存，正常情况下是没有必要跟flush privileges 的； 不规范的操作，直接使用DML操作系统权限表才需要跟flush privileges；  分区表  对于引擎层来说，分区表是多个表；对于Server层来说分区表是一个表 不建议使用分区表的原因： MySql在第一次打开分区表的时候需要访问所有的分区 在Server层认为是同一张表，因此公用同一个MDl锁，执行DDL时，影响更大  自增ID  如果没有指定自增ID，MySql会创建一个不可见的长度为6个字节的row_id; 当row_id达到最大值(2^48 -1)后，再申请row_id就是0，并且会覆盖原来的数据 redolog 和 binlog中的Xid（Server层维护）是事务中执行的第一个Sql的query_id, global_query_id 是一个内存变量，重启后会清零，但同时也会生成新的binlog文件，所以同一个binlog文件中的xid是唯一的 Innodb trx_id 事务ID是引擎层维护的，最大值2^48-1, 只读事务不分配trx_id，理论上，只要MySql运行的足够久，trx_id重新从0开始分配就会出现幻读  ]]></content></entry><entry><title>计算广告</title><url>/post/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/</url><categories><category>读书笔记</category></categories><tags><tag>计算广告</tag></tags><content type="html">术语解释 DMP 数据管理平台 ADX 广告交易平台 SSP 供给方平台 DSP 需求方平台 计算广告系统架构 广告投放引擎的主要模块 广告投放机 广告检索 广告排序 收益管理 广告请求接口 定制化用户划分 数据告诉公路 将在线投放的数据准实时的传输到离线分布式计算平台与流计算平台供后续处理和建模使用
离线数据处理 目标 统计日志得到报表； 利用数据挖掘、机器学习技术进行受众定向、点击率估计、分配策略规划等
用户会话日志生成 行为定向 上下文定向 点击率建模 分配规划 商业智能 广告管理系统 在线数据处理 离线数据处理的镜像功能
在线反作弊 计费 在线行为反馈 实时索引 广告相关领域知识 信息检索 倒排索引 向量空间模型-最基础且最重要的文档相似度度量方法 最优化 拉格朗日法与凸优化 梯度下降法 拟牛顿法 机器学习 最大熵与指数族分布 混合模型和EM算法 贝叶斯学习</content></entry><entry><title>Laravel中间件实现分析</title><url>/post/laravel%E4%B8%AD%E9%97%B4%E4%BB%B6/</url><categories><category>Laravel</category></categories><tags><tag>Laravel</tag></tags><content type="html"><![CDATA[Laravel的中间件提供了一种方便的机制过滤进入应用程序的 HTTP 请求，并且Laravel自带了一些中间件包括身份验证、CSRF保护、COOKIE加密解密等，使用非常方便。那么Laravel中“中间件”是怎么实现的，为什么只需要简单修改几个配置就能试中间件生效，中间件的执行顺序又是怎样的呢。出于对这些问题的好奇，我阅读了一下Laravel中间件的实现相关源码。
 \Illuminate\Pipeline\Pipeline - 实现中间件的核心类
 在介绍Pipeline这个类之前，我们先简单浏览一下Laravel应用程序的 生命周期  。接下里我一步一步的说明如何实例化Pipeline方法的。
 在入口文件index.php只有几行代码  $app = require_once __DIR__.&#39;/../bootstrap/app.php&#39;;  $kernel = $app-&gt;make(Illuminate\Contracts\Http\Kernel::class);  $response = $kernel-&gt;handle(  $request = Illuminate\Http\Request::capture() );  $response-&gt;send(); $kernel-&gt;terminate($request, $response); 首先实例化了一个Illuminate\Contracts\Http\Kernel，在bootstrap/app.php文件中， Illuminate\Contracts\Http\Kernel接口已经被绑定了App\Http\Kernel类，所以这里的$kernel是一个App\Http\Kernel的对象
bootstrap/app.php
// 此处对Illuminate\Contracts\Http\Kernel进行类绑定 $app-&gt;singleton(  Illuminate\Contracts\Http\Kernel::class,  App\Http\Kernel::class );  $app-&gt;singleton(  Illuminate\Contracts\Console\Kernel::class,  App\Console\Kernel::class );  $app-&gt;singleton(  Illuminate\Contracts\Debug\ExceptionHandler::class,  App\Exceptions\Handler::class );  return $app; 然后接着往下看，调用了Kernel的handel方法，并传入了一个Request对象。
class Kernel implements KernelContract ... /**  * Handle an incoming HTTP request.  *  * @param \Illuminate\Http\Request $request  * @return \Illuminate\Http\Response  */  public function handle($request)  {  try {  $request-&gt;enableHttpMethodParameterOverride();   $response = $this-&gt;sendRequestThroughRouter($request); // sendRequestThroughRouter 方里面实例化了Pipeline  } catch (Exception $e) {  $this-&gt;reportException($e);   $response = $this-&gt;renderException($request, $e);  } catch (Throwable $e) {  $this-&gt;reportException($e = new FatalThrowableError($e));   $response = $this-&gt;renderException($request, $e);  }   $this-&gt;app[&#39;events&#39;]-&gt;dispatch(  new Events\RequestHandled($request, $response)  );   return $response;  }   /**  * Send the given request through the middleware / router.  *  * @param \Illuminate\Http\Request $request  * @return \Illuminate\Http\Response  */  protected function sendRequestThroughRouter($request)  {  $this-&gt;app-&gt;instance(&#39;request&#39;, $request);   Facade::clearResolvedInstance(&#39;request&#39;);   $this-&gt;bootstrap();  ## 这里实例化了Pipeline  return (new Pipeline($this-&gt;app))  -&gt;send($request)  -&gt;through($this-&gt;app-&gt;shouldSkipMiddleware() ? [] : $this-&gt;middleware)  -&gt;then($this-&gt;dispatchToRouter());  } ... 接下来就到中间件的核心了- Pipeline-&gt;then()方法
public function then(Closure $destination)  {  $pipeline = array_reduce(  array_reverse($this-&gt;pipes), $this-&gt;carry(), $this-&gt;prepareDestination($destination)  );   return $pipeline($this-&gt;passable);  } 最关键的就是array_reduce()，函数原型：array_reduce ( array $array , callable $callback [, mixed $initial = NULL ] ) : mixed
 array_reduce() 将回调函数 callback 迭代地作用到 array 数组中的每一个单元中，从而将数组简化为单一的值。 一般情况下，我们第二个参数返回的是一个基本的数据类型，比如：
 $arr = [1, 2, 3, 4, 5]; $sum = array_reduce($arr, function($carry, $item) {  return $carry + $item; }, 0); echo $sum; // 结果为 15 那么如果我们第二个参数放回一个闭包函数会是什么样呢？
$arr = [&#34;item1&#34;, &#34;item2&#34;, &#34;item3&#34;]; $closure = array_reduce($arr, function ($carry, $item) {  return function () use ($carry, $item) {  dump($item);  if (is_null($carry)) {  return &#34;carry is null &#34; . $item;  }  if($carry instanceof Closure) {  dump($carry());  return $item . &#39;++&#39;;  }  }; }); dump(&#34;r:&#34;); dump($closure()); 结果为：
&ldquo;r:&rdquo;
&ldquo;item3&rdquo;
&ldquo;item2&rdquo;
&ldquo;item1&rdquo;
&ldquo;carry is null item1&rdquo;
&ldquo;item2++&rdquo;
&ldquo;item3++&rdquo;
为什么是这个结果呢？array_reduce返回的是一个闭包，只有执行这个闭包函数，里面的逻辑才会执行，所以相当于是把函数暂存起来了，类似于存到了一个栈中。
理解了array_reduce,然后我们看一下Laravel中carry()函数每次都返回了什么，打印一下每次调用的的 pipe 和 method:
输出：
所有carry方法每次都返回了我们配置了的中间件的handle方法，而$pipeline 就是一个由众多handle方法组成的闭包函数，然后执行
return $pipeline($this-&gt;passable); 对当前的Request进行过滤。因为后从carry()中返回的方法会被先执行，所以 array_reverse($this-&gt;pipes) 对我们的中间件顺序进行了翻转，这样执行的顺序就和我们配置中间件的顺序一致了
 以上就是 Laravel 中间件的实现了
 ]]></content></entry><entry><title>Nginx介绍</title><url>/post/nginx%E4%BB%8B%E7%BB%8D/</url><categories><category>服务器</category></categories><tags><tag>MySql</tag></tags><content type="html">Nginx是什么 nginx 是一个免费的，开源的，高性能HTTP服务器和反向代理，以及IMAP / POP3代理服务器。NGINX以其高性能，稳定性，丰富的功能集，简单的配置和低资源消耗而闻名。与传统服务器不同的是，Nginx不依赖线程来处理请求，它使用了更加可扩展的异步事件驱动的架构，因此与其他的服务器相比，Nginx可以使用很少的内存来同时处理上千个请求。
netcraft 调查显示，到2019年8月nginx拥有超过31％的计算机市场份额，仅落后于Apache5.39%
Nginx可以做什么 1 基本HTTP服务 静态文件处理（如HTML静态网页），处理索引文件以及支持自动个索引 打开并自行管理文件描述符缓存 提供反向代理服务，并可以使用缓存加速反向代理，同时完成简单的负载均衡及容错 提供缘层FastCGI服务缓存机制，加速访问，同时完成简单的负载均衡及容错 过滤器功能，Nginx基本过滤器有：gzip压缩、ranges支持、chunked支持、XSTL、SSI、以及图像缩放等 支持SSL 2 高级HTTP服务 基于名字和IP的虚拟主机设置 支持HTTP/1.0中的KEEP-ALIVE模式和PipeLined模型连接 支持重新加载配置及升级时无需中断正在处理的请求 自定义日志格式、带缓存的日志写操作以及快速日志轮转 提供3XX～5XX错误代码重定向功能 支持HTTP DAV模块，从而为HTTP WEBDAV提供PUT、DELETE、MKCOL、COPY、以及MOVE方法 支持FLV流和MP4传输 支持网络监控，基于客户端IP地址和HTTP基本认证机制的访问控制，速率限制，来自同一IP的同时连接数或请求限制等 支持Perl语言 邮件代理服务 使用外部HTTP认证服务器重定向 到用户的IMAP/POP3后端，并支持IMAP认证方式（LOGIN、AUTH LOGIN/PLAIN/CRAM-MD5）和POP3认证方式(USER/PASS、APOP、AUTH LOGIN/PLIAN/CRAM-MD5) 使用外部HTTP认证服务器认证用户后重定向到内部STMP后端，并支持 STMP认证方式 支持邮件代理服务下的安全套接层安全协议SSL 支持纯文本通信协议的扩展协议STARTTLS 优点 在Nginx之前市面上已经有Apache，tomcat，IIS等服务器 与这些Web服务器相比，Nginx具有高并发，低内存消耗的优势，Nginx在处理静态文件方面比其他服务器要优秀很多。
Nginx的Rewrite功能 地址重写与地址转发 在ngx_http_rewrite_module中 用法：
rewrite regex replacement [flag] flag 为 last，break，redirect，permanent
～ 大小写敏感 ～* 大小写不敏感
nginx 缓存
Proxy Store， Proxy Cache，基于memcache的缓存机制， Squid联合，第三方模块 ncache
Nginx 内存分配 当申请的内存大于4kb（一页内存的大小）时，该内存空间可用于分配的最大内存数据块不能超过4KB
Nginx服务器架构</content></entry><entry><title>MySql如何使用索引（二）</title><url>/post/mysql%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95%E4%BA%8C/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag></tags><content type="html"><![CDATA[  上篇 介绍了MySql什么时候会尝试使用索引，本文介绍一下我了解的不会使用索引的情况, 仍然使用上次建立好的表
 1. where 子句中like 使用了前缀通配符 %keyword  select * from test_user where name like &#34;%Kiven%&#34;; 2. 使用&gt;, &gt;=, &lt;,&lt;=, !=,NOT IN 范围查找或否定查找,且范围查找时选择的边界查找条件范围过大 select * from test_user where height&gt;=180 # 不会使用索引 select * from test_user where height&gt;=190 # 会使用索引 3. 数据类型隐式转换 例如：name字段为varchar类型的
select * from test_user where name=1 将不能使用索引，而
select * from test_user where name=&#39;1&#39; 可以使用索引
原因是当不同的字段类型比较时，MySql会做引式类型转换，而 int类型的1可能等于 &lsquo;01&rsquo;, &lsquo;0001&rsquo;或者 &lsquo;01.e1&rsquo;
4. 不符合最左匹配原则（联合索引） 我们建立的索引顺序是
KEY `idx_name_height_weight` (`name`,`height`,`weight`) 所以使用的时候where子句也不能跳过前一个联合索引列
# 比如直接联合索引的最后一列是不支持的 select * from test_user where weight=65 # 而使用全部索引列做查询条件是可以的 select * from test_user where weight=65 AND name=&#39;Tom&#39; AND `height`=160 6. 在索引列上进行运算 select * from test_user where `height`+10=160 #是不会使用索引的，可以写成 select * from test_user where `height`=160-10 # 就能够使用索引了  在索引使用方面MySql本身帮我们做了很多优化，有时候不一定会按照我们的想法去使用索引，接下来还需要探索
 ]]></content></entry><entry><title>MySql如何使用索引（一）</title><url>/post/mysql%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95%E4%B8%80/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag></tags><content type="html"><![CDATA[ 我们都知道在 MySql 中使用索引可以提高查询效率,但有时候真正执行Sql查询的时候却没有按照我们的预想使用索引，而是全表扫描，导致有慢Sql影响了整个网站的效率，甚至导致网站崩溃，所以我们需要了解Mysql是如何选择使用索引的，以便建立合适的索引 （本文基于MySql5.7，InnoDB引擎）
 前提：建立一张测试表 假设有一张用户表
CREATE TABLE `test_user` (  `user_id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) NOT NULL DEFAULT &#39;&#39;,  `birthday` date NOT NULL,  `sex` tinyint(1) DEFAULT NULL,  `height` int(11) NOT NULL,  `weight` int(11) NOT NULL,  PRIMARY KEY (`user_id`),  KEY `idx_name_height_weight` (`name`,`height`,`weight`),  KEY `idx_height` (`height`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 我们建立了name,height,weight 的联合索引，插入测试数据
INSERT INTO `test_user` (`user_id`, `name`, `birthday`, `sex`, `height`, `weight`) VALUES 	(1, &#39;Tony&#39;, &#39;1991-01-01&#39;, 1, 176, 65), 	(2, &#39;Mary&#39;, &#39;1989-12-19&#39;, 2, 160, 50), 	(3, &#39;Tom&#39;, &#39;1996-05-29&#39;, 1, 180, 70), 	(4, &#39;Kiven&#39;, &#39;1994-08-09&#39;, 1, 190, 80), 	(5, &#39;John&#39;, &#39;1992-11-12&#39;, 1, 182, 75); 执行什么操作的时候Mysql会使用索引 查找与WHERE子句匹配的行 select * from test_user where name=&#39;mary&#39; 查看执行计划
可见使用了idx_name_height_weight索引
从表中删除一行数据  DELETE from test_user where name=&#39;mary&#39;; 查看执行计划
查找索引列的MIN()或MAX()的值  SELECT MIN(height) FROM `test_user` 这个和之前的执行计划不太一样，Select tables optimized away（选择要优化的表）实际就是优化到不能再优化的意思，在这种情况下，MySql把每个Key的MIN() 和 MAX()值替换成一个常量，如果查到了这个常量就立即返回，然后看下面的例子，分别在索引列上和非索引列上使用MIN()函数的执行计划：
 SELECT MIN(height) from `test_user` where height&gt;=176 AND height&lt;=190;  SELECT MIN(height) from test_user where sex=1; 在索引列上执行 SORT 或 ORDER BY 操作  SELECT name,height from test_user ORDER BY `name` DESC; 注意SELECT的字段能匹配索引列，比如：
将会出现Using filesort，Using filesort 是Mysql里一种速度比较慢的外部排序，应当尽量避免
 本文讲述了MySql什么时候会使用索引，下章说明什么时候MySql不能使用索引， 点此查看 
 ]]></content></entry><entry><title>Linux命令之sed</title><url>/post/sed/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[sed 流处理编辑器  行处理一次只处理一行数据 （sed处理文件内容的核心思想） 不改变文件内容（除非重定向）  命令行格式 sed [option] 'command' file(s)  脚本格式 sed -f scriptfile file(s)  sed 命令 p 打印命令 -n 只打印匹配的行  定位一行 	sed -n &#39;2p&#39; test.txt 定位多行 	sed -n &#39;2,5p&#39; test.txt 	// (2和5也可以用正则代替) 定位反向选择 	sed -n &#39;2,5!p&#39; test.txt // 第2-5行不被选择 定位间隔几行 	sed -n &#39;2~2p&#39; test.txt // 间隔输出 行命令  a （新增行）/ i（插入行） c（替代行） d（删除行）  linux 用法 sed -n &#34;2a text2++&#34; test.txt sed -n &#34;2,5a text2++&#34; test.txt mac os 用法 sed -n &#34;2a \ text2++ &#34; test.txt  sed -n &#34;2,5a \ text2++ &#34; test.txt 替换命令 s - sed命令的核心 基本命令
sed &#39;s/search/replace&#39; filename （每行替换一次） 全局替换
sed &#39;s/search/replace/g&#39; filename eg:获取本机IP地址
ifconfig en0 | sed -n &#39;/inet /p&#39; | sed &#39;s/inet //&#39; | sed &#39;s/netmask.*$//&#39; sed高级命令 假设有如下文本 test.txt
 {} : 多个sed命令，用;分开  # 删除1，2行，并将5替换为12 sed &#34;{1,2d;s/5/12/}&#34; test.txt  n 读取下一个输入行，用下一个命令处理  隔行输出 与 sed -n &#39;2~2p&#39; test.txt 效果相同 sed -n &#34;{n;p}&#34; // 打印偶数行 sed -n &#34;{p;n}&#34; // 打印奇数行  &amp; 替换固定字符串   sed &#39;s/[a-z]\+/&amp;-/&#39; test.txt  // &amp;符号代替了前面的正则表达式匹配到的内容  u/l/U/l 大小写转换  u 首字母大些 l 首字母小写 U 单词大写 L 单词小写    sed &#39;s/[a-z]\+/\u&amp;/&#39; test.txt  () 获取匹配的内容  # 获取文件中的所有小写字符 sed &#39;s/\([a-z]\+\).*$/\1/&#39; test.txt # 获取本机ip ifconfig en0 | sed -n &#39;/inet /p&#39; | sed &#39;s/inet \([0-9.]\+\) .*$/\1/&#39;  r 复制指定文件到匹配行 w 复制匹配行到指定文件   再添加一个测试文件123.txt
 把test.txt文件内容写到123.txt中，如果需要指定行，在w前加行号
 attention： w 会改写文件，使用是应慎重
  q 退出sed  第5行后退出sed sed 还有一个重要的选项 -i: 直接修改读取的文件内容，而不是输出到终端
sed -i &#39;s/5/13/&#39; test.txt  更多用法请查看 gnu sed 官方文档 
 ]]></content></entry><entry><title>Linux 命令之 Awk</title><url>/post/awk/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[awk 文本处理工具  可编程，功能强大 可以用来统计，制表等功能  处理方式  一次处理一行内容 可以对每行进行切片处理  格式  命令行格式 awk [options] &#39;command&#39; file(s)  脚本格式 awk -f script_file file(s)   内置参数  $0 当前整行 $1 每行第一个字段 $2 每行第二个字段 NR 行号 NF 字符总数 FILENAME 文件名 ARGC 命令行参数个数 ARGV 命令行参数数组   -F 指定分割符，默认空格
awk -F &#39;:&#39; &#39;{print $1,$3, NR}&#39; test.txt // 以: 分割  awk -F &#39;:&#39; &#39;{if ($3&gt;100) print &#34;This Msg&#34;}&#39; test.txt 正则匹配 ～ ， 不匹配(！～) 打印第一个字符以m开头的  BEGIN 行处理前执行 END 行处理完成后执行 eg：文件夹大小求和    AWK 是一种程序设计语言，语法和C语言相似，把AWK命令写到脚本文件中可以完成更复杂的文本处理
 ]]></content></entry><entry><title>设计模式之命令模式</title><url>/post/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/</url><categories><category>设计模式</category></categories><tags><tag>设计模式</tag></tags><content type="html"><![CDATA[定义 将“请求”封装成命令对象，以便使用不同的请求，队列或者日志来参数化其他对象。命令模式也支持可撤销的操做。
适用场景 当需要将发出请求的对象和执行请求的对象解耦的时候，使用命令模式。比如我们有一个遥控器，需要控制客厅灯的点亮和关闭，电视的打开和关闭，风扇的关闭等，这是需要遥控器判断当前的对象类型，并执行不同的操作，此时就可以使用命令模式将遥控器和电灯，电视，风扇解耦
举个例子 假设有一下三个类，分别表示电灯，电风扇和电视：
/**  * Class Light  */ class Light {  public function on()  {   }  public function off()  {   } }  /**  * Class ElectricFan  */ class ElectricFan {  public function on()  {   }  public function off()  {   }  public function speedHigh()  {   }  public function speedLow()  {   } } /**  * Class Television  */ class Television {  public function on()  {   }  public function off()  {   }  public function voiceHigh()  {   }  public function voiceLow()  {   } } 按照一般的写法，当我们需要在实现遥控器类的时候可能会这样写
/**  * Class RemoteControl  */ class RemoteControl {  private $light;  private $electricFan;  private $television;   public function __construct(Light $light, ElectricFan $electricFan, Television $television)  {  $this-&gt;light = $light;  $this-&gt;electricFan = $electricFan;  $this-&gt;television = $television;  }   public function lightOn()  {  $this-&gt;light-&gt;on();  }   public function lightOff()  {  $this-&gt;light-&gt;Off();  }   // other function  ... } 可以看出来，当需要让遥控器遥控另一个电器，则还需要修改遥控器类的实现，是不是很麻烦。
使用命令模式实现遥控器类 既然上面的写法比较麻烦，每次都需要修改控制器的代码，那么换个思路把每一个命令作为一个对象来实现。仍然使用上面的三个被遥控的电器类，但这次我们把没一个命令作为一个对象
interface Command {  public function execute(); }  /** * 开灯 * Class LightOnCommand * @package App */ class LightOnCommand implements Command {  private $light;  public function __construct(Light $light)  {  $this-&gt;light = $light;  }  public function execute()  {  $this-&gt;light-&gt;on();  } }  /** * 关灯 * Class LightOffCommand * @package App */ class LightOffCommand implements Command {  private $light;  public function __construct(Light $light)  {  $this-&gt;light = $light;  }  public function execute()  {  $this-&gt;light-&gt;off();  } }  /** * 开风扇 * Class ElectricFanOnCommand * @package App */ class ElectricFanOnCommand implements Command {  private $electricFan;  public function __construct(ElectricFan $electricFan)  {  $this-&gt;electricFan = $electricFan;  }  public function execute()  {  $this-&gt;electricFan-&gt;on();  } }  /** * 关风扇 * Class ElectricFanOffCommand * @package App */ class ElectricFanOffCommand implements Command {  private $electricFan;  public function __construct(ElectricFan $electricFan)  {  $this-&gt;electricFan = $electricFan;  }  public function execute()  {  $this-&gt;electricFan-&gt;off();  } }  /** * 开电视 * Class ElectricFanOnCommand * @package App */ class TelevisionOnCommand implements Command {  private $television;  public function __construct(Television $television)  {  $this-&gt;electricFan = $television;  }  public function execute()  {  $this-&gt;television-&gt;on();  } }  /** * 关电视 * Class ElectricFanOffCommand * @package App */ class TelevisionOffCommand implements Command {  private $television;  public function __construct(Television $television)  {  $this-&gt;electricFan = $television;  }  public function execute()  {  $this-&gt;television-&gt;off();  } }  // 其他的命令类似 这样我们就可以这样实现遥控器类
class RemoteControl {  private $onCommand = [];  private $offCommand =[];   /**  * RemoteControl constructor.  * @param array $onCommand Command 数组  * @param array $offCommand Command 数组  */  public function __construct()  {  }   public function setCommand(int $position, Command $onCommand, Command $offCommand)  {  $this-&gt;onCommand[$position] = $onCommand;  $this-&gt;offCommand[$position] = $offCommand;  }   /**  * 打开  */  public function pressOn()  {  foreach ($this-&gt;onCommand as $command) {  $command-&gt;execute();  }  }   /**  * 关闭  */  public function pressOff()  {  foreach ($this-&gt;offCommand as $command) {  $command-&gt;execute();  }  } } 现在来实现一下打开和关闭电灯
$light = new Light(); $lightOnCommand = new LightOnCommand($light); $lightOffCommand = new LightOffCommand($light); $remoteControl = new RemoteControl(); $remoteControl-&gt;setCommand(0, $lightOnCommand, $lightOffCommand); $remoteControl-&gt;pressOn(); $remoteControl-&gt;pressOff(); 当需要遥控器控制电视的时候：
$remoteControl = new RemoteControl(); // 电灯 $light = new Light(); $lightOnCommand = new LightOnCommand($light); $lightOffCommand = new LightOffCommand($light); $remoteControl-&gt;setCommand(0, $lightOnCommand, $lightOffCommand); // 电视 $television = new Television(); $televisionOnCommand = new TelevisionOnCommand($television); $televisionOffCommand = new TelevisionOffCommand($television); $remoteControl-&gt;setCommand(1, $televisionOnCommand, $televisionOffCommand); // 打开 $remoteControl-&gt;pressOn(); // 关闭 $remoteControl-&gt;pressOff(); 这样遥控器的代码不用做任何修改，就可以添加控制更多的电器，降低了两者的耦合。
用途 命令模式可以用于 队列请求， 比如有一个工作队列，在一端添加命令，另一端取出命令调用它的execute()方法，执行完成后再去取下一个命令
总结  命令模式将发出请求的对象和执行请求的对象解耦 在被解耦的两者之间是通过命令对象进行沟通的。命令对象封装了接收者的一个或一组动作 调用者可以接受命令当作参数，甚至在运行时动态的进行  ]]></content></entry><entry><title>如何构建并发系统</title><url>/post/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/</url><categories><category>GOLANG</category></categories><tags><tag>go</tag></tags><content type="html"> 本文简单说明几个设计并发系统时需要考虑的问题，内容摘抄自《GO语言并发之道》
异常传递 异常是什么，什么时候发生，提供了哪些好处
首先，异常需要传达几个关键信息：
发生了什么： 这部分异常信息包括了岁异常时间的描述。例如：磁盘已满，连接被重置，证书过期等 发生在什么时间，什么位置： 异常应该包含完整的轨迹信息，从调用的启动方式开始，已异常的实例结尾。栈轨迹信息不应该被包含在异常信息中，但当需要处理栈中的异常时应该很容易被找到 对用户友好的信息：应当对展现给用户的信息进行自定义，应该只包含前两点的概述以及相关信息。对用户友好的信息是从用户的角度出发，给出一些信息，说明这些信息是否是暂时的，并且最好是一行以内的文本 告诉用户如何获取更多信息：某些情况下，用户希望知道当异常发生时具体发生了那些故障，展示给用户的异常信息应该提供一个id，利用这个id可以查到对应的详细日志，日志应该包含有完整的信息（异常的发生时间和异常时的堆栈调用） 当展示给用户的信息不包含这些信息，不是出错了就是有BUG。所以异常可以分为两类：
BUG 已知信息 超时和取消 为什么要支持超时？ 系统饱和 如果系统已经饱和（已经达到系统处理请求的能力），希望可以返回超时，而不是花很长的时间等待响应。
陈旧的数据 数据通常有一个窗口期，一般是在这个窗口中先处理更多相关数据或者处理数据的需求已经过期。 如果知道窗口期，那么将context.WithDeadline或context.WithTimeout创建的context传递给并发进程是有意义的，如果事先不知道窗口，我们希望并发进程的父节点能够在不再需要时取消并发进程。context.WithCancel是达到这个目的的最佳选择
试图防止死锁 通过设置超时可以将一个死锁系统转变为一个活锁系统，在系统死锁后，很可能会遇到时序配置不同步的情况。因此最好是在允许饿时间内修复活锁，好过发生死锁后只能通过重启系统才能恢复系统
这不是如何正确构建系统的建议，而是如何建立一个对时间问题有容错能力的系统
什么时候应当设置超时 请求在超时时不太可能重复 没有资源来存储请求 对系统的响应或请求发送数据有时效性要求 并发进程可能被取消的原因 超时-隐式取消 用户干预 父进程取消：如果父进程停止，那子进程也将被取消 复制请求：将数据发送给多个并发进程，以尝试从其中一个系统获得更快的响应。当第一个响应回来的时候，取消其余的进程。 心跳 心跳是并发进程向外界发出信号的一种方式。
心跳类型 在一段时间间隔内发出的心跳 在工作单元开始时发出的心跳 golang通过channel发送心跳的时候，需要注意有可能没有人接收发出去的心跳（因为心跳不一定重要）
复制请求 某些情况下，可以将请求分发到多个处理程序（goroutine，进程，或者服务器均可），其中一个将比其他程序更快的返回结果，这样就可以立即返回结果。但是会消耗更多的资源。当多个处理程序需要多个进程，服务器，或者数据中心时，代价会相当昂贵，所以要权衡是否值得这么做
速率限制 为什么需要速率限制 通常对系统进行限速，可以避免系统被攻击，如果恶意用户在资源允许的情况下可以频繁访问系统，他们可以做各种事情。比如：使用日志或有效请求打满服务器磁盘，或者DDos攻击。 速率限制可以将系统的性能和稳定性平衡在可控范围内
如何限速 大多数是基于令牌桶算法的，相对容易实现。golang中 golang.org/x/time/rate [github 地址] 包实现了这个功能
治愈异常的goroutine 在一个长期运行的程序中，建立一个机制来监控你的goroutine是否处于健康状态是很有用的，当goroutine异常时，可以尽快的重启。重启的过程成为“治愈”（Healing）。
如何治愈goroutine？ 使用心跳模式检查我们正在监控的goroutine是否活跃。我们需要一个管理员来监视一个管理区的goroutine，如果有goroutine变得不健康，管理员负责重启这个管理区的goroutine。</content></entry><entry><title>MySql 修改表结构时 ALTER,MODIFY,CHANGE的区别</title><url>/post/mysql-%E4%BF%AE%E6%94%B9%E8%A1%A8%E7%BB%93%E6%9E%84%E6%97%B6-alter-modify-change%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag></tags><content type="html">根据MySql文档，我们知道在修改表内某一列的属性的时候，MySql支持3中语法结构：
ALTER [ONLINE|OFFLINE] [IGNORE] TABLE tbl_name ALTER [COLUMN] col_name {SET DEFAULT literal | DROP DEFAULT} ALTER [ONLINE|OFFLINE] [IGNORE] TABLE tbl_name CHANGE [COLUMN] old_col_name new_col_name column_definition [FIRST|AFTER col_name] ALTER [ONLINE|OFFLINE] [IGNORE] TABLE tbl_name MODIFY [COLUMN] col_name column_definition [FIRST | AFTER col_name] 这里比较一下这三种语法的不同之处，以及什么情况下应该选用什么语法
语法 功能 说明 ALTER 只能更改列的默认值 CHANGE 可以重命名列或者修改列的定义 标准SQL的扩展 MODIFY 可以更改列的定义，但不能更改列的名称 兼容Oracle的扩展 通过文档介绍的功能，我们就基本能够判断处该使用使用哪种语法，CHANGE功能最强大，什么情况下都可以使用(达到预期的效果)。但是还有一个区别： ALTER 语法只是修改 .frm 文件，不会去更新表中的数据； MODIFY和CHANGE在更新表结构的时候重新插入表中的数据，因此比较耗费时间。 所以，当只需要修改某一列的默认值的时候，优先选择用ALTER，需要修改列的名称用CHANGE，只修改列的定义用MIODIFY
如果修改的列上有索引，修改完后最好重建一下索引</content></entry><entry><title>Laravel Facades 门面模式的实现</title><url>/post/laravel-facades-%E9%97%A8%E9%9D%A2%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AE%9E%E7%8E%B0/</url><categories><category>php</category><category>laravel</category></categories><tags><tag>php</tag><tag>laravel</tag></tags><content type="html"><![CDATA[ 以下是Laravel官方文档的介绍
 Facades 为应用程序的 服务容器 中可用的类提供了一个「静态」接口。Laravel 本身附带许多的 facades，甚至你可能在不知情的状况下已经在使用他们！Laravel 「facades」作为在服务容器内基类的「静态代理」，拥有简洁、易表达的语法优点，同时维持着比传统静态方法更高的可测试性和灵活性。
从介绍中可以看出，Facades 好处就是让代码更加简介，优雅，这也是Laravel追求的特性，如何使用Facades这里就不介绍了，可以参考 Laravel文档(中文)   ，本文介绍一下Facades是如何知道和创建你需要的类实例。
以 log Facade 为例，我们看下是如何通过log这个字符串找到 \Illuminate\Log\Writer 这个类的 先看 \Illuminate\Support\Facades\Log 门面
class Log extends Facade {  /**  * Get the registered name of the component.  *  * @return string  */  protected static function getFacadeAccessor()  {  return &#39;log&#39;;  } } 这个类非常简单，只有一个静态方法 getFacadeAccessor(), 返回了一个log字符串。 然后看Log的父类 Facade, Facede中有很多方法，这里关注其中两个：
abstract class Facade {  /**  * The application instance being facaded.  *  * @var \Illuminate\Contracts\Foundation\Application  */  protected static $app;   /**  * The resolved object instances.  *  * @var array  */  protected static $resolvedInstance; 		/**  * Resolve the facade root instance from the container.  *  * @param string|object $name  * @return mixed  */  protected static function resolveFacadeInstance($name)  {  if (is_object($name)) {	// 如果$name已经是一个对象，则直接返回该对象  return $name;  }   if (isset(static::$resolvedInstance[$name])) {	// 如果是已经解析过的对象，直接从$resolvedInstance中返回该对象  return static::$resolvedInstance[$name];  }   return static::$resolvedInstance[$name] = static::$app[$name]; // 从容器中寻找$name对象，并放入$resolvedInstance 中以便下次使用  } 	/**  * Handle dynamic, static calls to the object.  *  * @param string $method  * @param array $args  * @return mixed  *  * @throws \RuntimeException  */  public static function __callStatic($method, $args)	// 魔术方法，当使用Log::error($msg) 的时候会调用该方法  {  $instance = static::getFacadeRoot();   if (! $instance) {  throw new RuntimeException(&#39;A facade root has not been set.&#39;);  }   switch (count($args)) {  case 0:  return $instance-&gt;$method();  case 1:  return $instance-&gt;$method($args[0]);  case 2:  return $instance-&gt;$method($args[0], $args[1]);  case 3:  return $instance-&gt;$method($args[0], $args[1], $args[2]);  case 4:  return $instance-&gt;$method($args[0], $args[1], $args[2], $args[3]);  default:  return call_user_func_array([$instance, $method], $args);  }  } } 通过以上分析知道最终Facede找的是容器中绑定的实例，所以接下来我们找一下log是在什么时候被注册的，
这时候需要关注 \Illuminate\Foundation\Http\Kernel 类,Kernel类中包括以下几个方法：
/** * Handle an incoming HTTP request. * * @param \Illuminate\Http\Request $request * @return \Illuminate\Http\Response */ public function handle($request) { 	try { 	$request-&gt;enableHttpMethodParameterOverride();  	$response = $this-&gt;sendRequestThroughRouter($request); 	} catch (Exception $e) { 	$this-&gt;reportException($e);  	$response = $this-&gt;renderException($request, $e); 	} catch (Throwable $e) { 	$this-&gt;reportException($e = new FatalThrowableError($e));  	$response = $this-&gt;renderException($request, $e); 	}  	$this-&gt;app[&#39;events&#39;]-&gt;fire(&#39;kernel.handled&#39;, [$request, $response]);  	return $response; } 		/** * Send the given request through the middleware / router. * * @param \Illuminate\Http\Request $request * @return \Illuminate\Http\Response */ protected function sendRequestThroughRouter($request) { 	$this-&gt;app-&gt;instance(&#39;request&#39;, $request);  	Facade::clearResolvedInstance(&#39;request&#39;);  	$this-&gt;bootstrap();  	return (new Pipeline($this-&gt;app)) 	-&gt;send($request) 	-&gt;through($this-&gt;app-&gt;shouldSkipMiddleware() ? [] : $this-&gt;middleware) 	-&gt;then($this-&gt;dispatchToRouter()); }  /** * Bootstrap the application for HTTP requests. * * @return void */ public function bootstrap() { 	if (! $this-&gt;app-&gt;hasBeenBootstrapped()) { 	$this-&gt;app-&gt;bootstrapWith($this-&gt;bootstrappers()); 	} } handle方法接收一个Request请求，并返回一个$response，$response-&gt;sendRequestThroughRouter()的时候调用了bootstrap()方法，继续看bootstrap方法里面加载了已经定义好的几个类：(这些定义都在Kernel类中)
/** * The bootstrap classes for the application. * * @var array */ protected $bootstrappers = [ 	&#39;Illuminate\Foundation\Bootstrap\DetectEnvironment&#39;, 	&#39;Illuminate\Foundation\Bootstrap\LoadConfiguration&#39;, 	&#39;Illuminate\Foundation\Bootstrap\ConfigureLogging&#39;, 	&#39;Illuminate\Foundation\Bootstrap\HandleExceptions&#39;, 	&#39;Illuminate\Foundation\Bootstrap\RegisterFacades&#39;, 	&#39;Illuminate\Foundation\Bootstrap\RegisterProviders&#39;, 	&#39;Illuminate\Foundation\Bootstrap\BootProviders&#39;, ]; 然后我们看ConfigureLogging中的registerLogger()方法
/** * Register the logger instance in the container. * * @param \Illuminate\Contracts\Foundation\Application $app * @return \Illuminate\Log\Writer */ protected function registerLogger(Application $app) { 	$app-&gt;instance(&#39;log&#39;, $log = new Writer(	// 这里把Writer注册到了容器中 	new Monolog($app-&gt;environment()), $app[&#39;events&#39;]) 	);  	return $log; } 到此为止，我们已经知道Facede是如何找到想要使用的类了。 Facedes看起来挺高大上，但实现起来的原理挺简单的，实际上也是一种单例模式，只不过在调用处包装了一下
]]></content></entry><entry><title>校验码</title><url>/post/%E6%A0%A1%E9%AA%8C%E7%A0%81/</url><categories><category>计算机基础</category></categories><tags><tag>计算机基础</tag></tags><content type="html">为了保证计算机系统运行时数据在传输过程中正确无误，提高硬件电路的可靠性和提高代码的校验能力,通常使用校验码来检测传输数据是否出错，常用的3种校验码：
1. 奇偶校验 专门设置一个奇偶校验位来保证发出数据中的1的个数是奇数（或者偶数)， 缺点:只能发现有奇数个位出错的情况，不能发现有偶数个位出错的情况 2. 海明码校验 在数据的特定位置上插入 k 个校验位,假设原来的数据有n位，这样编码后的数据有n+k位，数据就会有n+k位出错和一种正确情况，所以k应该满足： 2^k - 1 &amp;gt;= n+k
检验码的位置都在数据的2^m位上 校验码的每一个值可以表示一位数据是否正确 将每个海明码出现的位置做异或运算，得到的结果就是出错的位置-进行取反操作 3. 循环冗余码校验 广泛用于数据通信领域和磁介质存储系统中.
循环冗余校验码原理： 发送端和接收端共同设置一个除数（生成多项式），通常最高位和最低位都是1，或者公式 G(x) = 2^x + 2^(x-1) + 1 在原数据后面添加n个校验位，n=除数的位数 -1 (校验位上存的是余数，所以不会比除数大) 发送端用原数据补充n-1个0后，对多项式进行模2运算，将余数放到校验位上 接收端用接收到的数据和多项式也进行模2运算，如果余数伟0，则数据正确，否则数据错误，需要发送端重传</content></entry><entry><title>PHP5与PHP7的zval比较</title><url>/post/php5%E4%B8%8Ephp7%E7%9A%84zval%E6%AF%94%E8%BE%83/</url><categories><category>php</category></categories><tags><tag>php</tag></tags><content type="html">PHP5中zval定义 struct _zval struct { zvalue_value value; // 16 zend_unit refcount_gc; // 4字节 引用计数 zend_uchar type; // 1 zend_uchar is_ref__gc; // 1 是否为引用类型 } typedef union _avalue_value { long lval; // 8 double dval; // 8 struct { char *val; int len; } str; // 16 HashTable *ht; // HashTable 数组 8 zend_object_value obj; // 12 zend_ast * ast; // 8 } zvalue_value; 为了解决循环引用问题，PHP5.3之后通过重写分配zval的宏，对zval进行扩充，新的分配方式：
#undef ALLOC_ZVAL #define ALLOC_ZVAL (z) do { (z) = (zval*) emalloc (sizeof(zval_gc_info)); GC_ZVAL_INT (z); } while(0) // _zval_gc_info 结构如下： typedef struct _zval_gc_info { zval z; union { gc_root_buffer *buffer; struct _zval_gc_info *next; } } 除此之外，在开启Zend内存池的情况下，zval_gc_info 在内存池中分配，内存池会为每个zval_gc_info额外申请一个大小为16字节的zend_mm_block结构体，用来存放内存相关信息，zend_mm_block结构如下：
typedef struct _zend_mm_block_info { size_t _size; size_t _prev; } zend_mm_block_info; typedef struct _zend_mm_block { zend_mm_block_info info; } zend_mm_block; 最终一个变量在PHP5中占内存大小为48个字节（48个字节其实有很多浪费），占用情况如图：
1.zend_mm_block 是啥 2.为什么会有循环引用的问题
PHP7的zval typedef union _zend_value { zend_long lval; /* long value */ double dval; /* double value */ zend_refcounted *counted; // 引用计数 zend_string *str; zend_array *arr; zend_object *obj; zend_resource *res; zend_reference *ref; zend_ast_ref *ast; zval *zv; void *ptr; zend_class_entry *ce; zend_function *func; struct { uint32_t w1; uint32_t w2; } ww; } zend_value; struct _zval_struct { zend_value value; /* value */ union { struct { ZEND_ENDIAN_LOHI_4( zend_uchar type, /* active type 记录变量类型*/ zend_uchar type_flags, zend_uchar const_flags, zend_uchar reserved) /* call info for EX(This) */ } v; /* 4字节 */ uint32_t type_info; // 4字节 其实type_info 就是v 中4个char的组合 } u1; union { uint32_t next; /* hash collision chain */ uint32_t cache_slot; /* literal cache slot */ uint32_t lineno; /* line number (for ast nodes) */ uint32_t num_args; /* arguments number for EX(This) */ uint32_t fe_pos; /* foreach position */ uint32_t fe_iter_idx; /* foreach iterator index */ uint32_t access_flags; /* class constant access flags */ uint32_t property_guard; /* single property guard 单一属性保护*/ uint32_t extra; /* not further specified 保留字段，暂无意义*/ } u2; }; PHP7的zval中value占8字节，u1占4字节，u2为辅助字段，占4字节，这样zval一共占16字节，即使没有u2，在内存对齐的情况下，zval也要占16字节，用u2记录了一些特殊信息，并不会浪费内存，反而是对内存的充分利用
PHP7 Z_VAL内存占用图</content></entry><entry><title>PHP 内核分析笔记（二）多进程与多线程SAPI生命周期</title><url>/post/php-%E5%86%85%E6%A0%B8%E5%88%86%E6%9E%90%E7%AC%94%E8%AE%B0%E4%BA%8C/</url><categories><category>php</category></categories><tags><tag>php</tag></tags><content type="html">多进程SAPI生命周期 以Apache为例，PHP编译为apache的一个模块来处理php请求，Apache启动后会fork多个进程，每个进程拥有独立的内存空间，单独处理php请求，所以每个子进程都是完整的生命周期 多线程的SAPI生命周期 同一组线程只有一个模块初始化和销毁的过程</content></entry><entry><title>PHP 内核分析笔记（一）单进程SAPI生命周期</title><url>/post/php-%E5%86%85%E6%A0%B8%E5%88%86%E6%9E%90%E7%AC%94%E8%AE%B0%E4%B8%80/</url><categories><category>php</category></categories><tags><tag>php</tag></tags><content type="html">http://www.php-internals.com/images/book/chapt02/02-00-php-
单进程SAPI生命周期 :start php -f test.php call each extension`s MINIT (模块初始化阶段，调用所有模块的MINIT函数) Request test.php call each extension`s RINIT (调用所有模块的RINIT函数) Execute test.php call each extension`s RSHUTDOWM Finsh cleaning up after test.php call each extension`s MSHUTDOWM （Web服务器退出或者命令行脚本执行完毕退出） terminate test.php :end 启动 模块初始化阶段 初始化若干全局变量 初始化若干常量，这里的常量是PHP自己的一些常量，如PHP_VERSION 初始化Zend引擎和核心组件 解析php.ini 全局操作函数的初始化 初始化静态构建的模块和共享模块(MINIT) 禁用函数和类 php_disable_functions, 其禁用的过程是调用zend_disable_function函数将指定的函数名从CG(function_table)函数表中删除,php_disable_classes,将指定的类名从CG(class_table)类表中删除 ACTIVATION 激活Zend引擎 激活SAPI 环境初始化 这里的环境初始化是指在用户空间中需要用到的一些环境变量初始化，这里的环境包括服务器环境、请求数据环境等。 实际到我们用到的变量，就是$_POST、$_GET、$_COOKIE、$_SERVER、$_ENV、$_FILES。 和sapi_module.default_post_reader一样，sapi_module.treat_data的值也是在模块初始化时， 通过php_startup_sapi_content_types函数注册了默认数据处理函数为main/php_variables.c文件中php_default_treat_data函数 模块请求初始化 (Call each extension&amp;rsquo;s RINIT) 运行 php_execute_script 函数包含了运行PHP脚本的全部过程 DEACTIVATION PHP关闭请求的过程是一个若干个关闭操作的集合，这个集合存在于php_request_shutdown函数中 1. 调用所有通过register_shutdown_function()注册的函数 2. 执行所有可用的__destruct函数 3. 将所有的输出刷出去 4. 发送HTTP应答头 5. 遍历每个模块的关闭请求方法 call each extension`s RSHUTDOWM 6. 销毁全局变量表（PG(http_globals)）的变量 7. 通过zend_deactivate函数，关闭词法分析器、语法分析器和中间代码执行器 8. 调用每个扩展的post-RSHUTDOWN函数 9. 关闭SAPI，通过sapi_deactivate销毁SG(sapi_headers)、SG(request_info)等的内容 10. 关闭流的包装器、关闭流的过滤器 11. 关闭内存管理 12. 重新设置最大执行时间 结束 flush 关闭Zend引擎 在关闭所有的模块后，PHP继续销毁全局函数表，销毁全局类表、销售全局变量表等。 通过zend_shutdown_extensions遍历zend_extensions所有元素，调用每个扩展的shutdown函数</content></entry><entry><title>PHP 知识总结（一）</title><url>/post/php-summarize/</url><categories><category>php</category></categories><tags><tag>php</tag></tags><content type="html"><![CDATA[语法基础 变量类型  boolean integet float # 判断是否是一个数值类型 bool is_nan(float $val)  string   // 字符串转数值  //如果 字符串中包含 &#39;.&#39;, &#39;e&#39;或者&#39;E&#39; 转换为float，其余转为 int Array // 数组的key只能是int 或string 合法的整型字符串会被转成int，例如：&#34;8&#34;，&#34;08&#34;不会，因为08不是合法的十进制数 浮点数也会被转换为整型，意味着其小数部分会被舍去。例如键名 8.7 实际会被储存为 8。 布尔值也会被转换成整型。即键名 true 实际会被储存为 1 而键名 false 会被储存为 0。 Null 会被转换为空字符串，即键名 null 实际会被储存为 &#34;&#34;。 数组和对象不能被用为键名。坚持这么做会导致警告：Illegal offset type 默认键： 当前最大整数索引值加1 // 其他类型转为数组 $a = array($a); or $a = (array) $a; 如果一个 object 类型转换为 array，则结果为一个数组，其单元为该对象的属性。键名将为成员变量名，不过有几点例外：整数属性不可访问；私有变量前会加上类名作前缀；保护变量前会加上一个 &#39;*&#39; 做前缀。这些前缀的前后都各有一个 NULL 字符。这会导致一些不可预知的行为： class A {  private $A; // This will become &#39;\0A\0A&#39; }  class B extends A {  private $A; // This will become &#39;\0B\0A&#39;  public $AA; // This will become &#39;AA&#39; }  var_dump((array) new B()); //上例会有两个键名为 &#39;AA&#39;，不过其中一个实际上是 &#39;\0A\0A&#39;  Object Reource 资源类型 资源 resource 是一种特殊变量，保存了到外部资源的一个引用 可以用 is_resource()函数测定一个变量是否是资源，函数 get_resource_type()则返回该资源的类型  NULL Callback/Callable  魔术方法 http://php.net/manual/zh/language.oop5.magic.php# ``` __construct()， __destruct()， __call()， __callStatic()， __get()， __set()， __isset()， __unset()， __sleep()， __wakeup()， __toString()， __invoke()， __set_state()， __clone() 和 __debugInfo() ```  运算符 算数运算符
$a ** $b 表示已$a的$b次方（PHP5.6之后支持）, $a ** $b = exp($a*log($a));
赋值运算符=
一般情况下赋值运算是将原变量的值拷贝到新变量中，但有个例外，就是碰到对象object时是引用赋值，除非明确使用clone关键字
]]></content></entry><entry><title>GO语言语法基础</title><url>/post/go-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url><categories><category>GOLANG</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[基础语法   i++, i&ndash; 在go语言中是语句，而不像其他语言一样是表达式，所以， j = i++ 在go语言里面是不合法的,并且只支持后缀， &ndash;i 是不合法的
  for 是go里面唯一的循环语句 传统的while循环写成 for condition {
}
  函数
函数的类型，称为函数签名，函数的实参都是按值传递的
  文件结束标示
err = errors.New(&#34;EOF&#34;) in := bufio.NewReader(os.stdin) for {  r,_,err = in.ReadRune()  if err == io.EOF {  break // 文本结束标记  }  if err != nil {  return fmt.Errorf(&#34;read failed: $v&#34;,err)  }  // 处理逻辑 } go 文本结束标记不怎么友好，为什么要放到error信息中
  数组 Go 语言中的数组是一种 值类型（不像 C/C++ 中是指向首元素的指针），所以可以通过 new() 来创建： var arr1 = new([5]int)。
那么这种方式和 var arr2 [5]int 的区别是什么呢？arr1 的类型是 *[5]int，而 arr2的类型是 [5]int。
这样的结果就是当把一个数组赋值给另一个时，需要在做一次数组内存的拷贝操作。例如：
arr2 := *arr1 arr2[2] = 100 这样两个数组就有了不同的值，在赋值后修改 arr2 不会对 arr1 生效。
==切片是引用类型，所以不能用指针指向切片==
  参数传递
go中所有的东西都是按值传递的，每次调用函数时，传入的数据都会被复制。对于具有值接收者的方法，在调用该方法时将复制该值。因为所有的参数都是通过值传递的，这就可以解释为什么 *Cat 的方法不能被 Cat 类型的值调用了。任何一个 Cat 类型的值可能会有很多 *Cat 类型的指针指向它，如果我们尝试通过 Cat 类型的值来调用 *Cat 的方法，根本就不知道对应的是哪个指针。
  go 并发编程 1. goroutine 和通道 程序启动时，只有一个 goroutine 来调用 main 函数，称为主 goroutine，新的 goroutine 通过 go 语句创建  ，就是在普通的函数或方法前加上 go 关键字，当 main 函数返回时，所有的 goroutine 都将暴力终止。
2. 缓冲通道 func mirroredQuery() string{ responses := make(chan string,3) go func() {responses &lt;- request(&quot;asia.gopl.io&quot;)}() go func() {responses &lt;- request(&quot;europe.gopl.io&quot;)}() go func() {responses &lt;- request(&quot;americas.gopl.io&quot;)}() return &lt;-responses //return the questest response } 主goroutine只接收第一个返回的，或者极端情况下，两个较慢的服务器还没有返回响应，就返回了结果 3. goroutine 泄漏
如果使用无缓冲通道，两个较慢的通道goroutine将被卡住（因为他们发送响应结果到通道没有goroutine来接收），这种情况叫goroutine泄漏。不要通过共享内存来通信，应该通过通信来共享内存
]]></content></entry></search>